{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>ðŸ’ŸINFORME MACHING LEARNINGðŸ’Ÿ</center>\n",
    "\n",
    "El objetivo de este informe es crear dos notebooks. Uno donde se utilice la tÃ©cnica de redes neuronales\n",
    "y otro para la tÃ©cnica de Ã¡rboles de decisiÃ³n, todo esto para determinar los hiperparÃ¡metros Ã³ptimos para obtener la mayor precisiÃ³n posible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ’ŸINTEGRANTESðŸ’Ÿ\n",
    "* Isabela Rosero 2128720\n",
    "* Luisa Cardenas 1823494 \n",
    "* Stefhania Noguera 2125854"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ’ŸIMPORTACIONESðŸ’Ÿ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ’ŸLEER EL ARCHIVO CSVðŸ’Ÿ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1: Leer el archivo breastCancer.csv\n",
    "\n",
    "data = pd.read_csv(\"breastCancer.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ’ŸSELECCIONAR EL 80% DEL CONJUNTO DE DATOS Y EL 20 PARA PRUEBASðŸ’Ÿ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2: Seleccionar aleatoriamente el 80% del conjunto de datos para entrenar y el 20% restante para las pruebas\n",
    "X = data.drop(\"diagnosis\", axis=1)\n",
    "y = data[\"diagnosis\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=123\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ’ŸNORMALIZAR LOS DATOSðŸ’Ÿ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "numericas = [\"radius_mean\",\n",
    "              \"texture_mean\", \n",
    "              \"perimeter_mean\", \n",
    "              \"area_mean\", \n",
    "              \"smoothness_mean\", \n",
    "              \"compactness_mean\", \n",
    "              \"symmetry_mean\", \n",
    "              \"fractal_dimension_mean\", \n",
    "              \"radius_worst\",\n",
    "              \"texture_worst\",\n",
    "              \"perimeter_worst\",\n",
    "              \"area_worst\",\n",
    "              \"smoothness_worst\",\n",
    "              \"compactness_worst\",\n",
    "              \"symmetry_worst\",\n",
    "              \"fractal_dimension_worst\",]\n",
    "\n",
    "\n",
    "num_transformer = Pipeline(\n",
    "    steps=[(\"imputer\", SimpleImputer(strategy=\"median\")), (\"scaler\", StandardScaler())]\n",
    ")\n",
    "\n",
    "modificacionesPreProcesado = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", num_transformer, numericas),\n",
    "    ]\n",
    ")\n",
    "\n",
    "X_train_processed = modificacionesPreProcesado.fit_transform(X_train)\n",
    "X_test_processed = modificacionesPreProcesado.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ’ŸCONFIGURAR LOS HPERPARAMETROS DEL ARBOLðŸ’Ÿ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "hiperparametro = range(1, 11, 1)\n",
    "\n",
    "arbolesDecisionPaso4 = []\n",
    "for max_depth in hiperparametro:\n",
    "    classifier = DecisionTreeClassifier(\n",
    "        criterion=\"gini\", splitter=\"best\", max_depth=max_depth, random_state=123\n",
    "    )\n",
    "    classifier.fit(X_train_processed, y_train)\n",
    "    arbolesDecisionPaso4.append(classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ’ŸTABLA CON LOS VALORESðŸ’Ÿ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabla de precisiÃ³n de Ã¡rboles punto 4\n",
      "   Profundidad mÃ¡xima  PrecisiÃ³n\n",
      "0                   1   0.929825\n",
      "1                   2   0.929825\n",
      "2                   3   0.956140\n",
      "3                   4   0.947368\n",
      "4                   5   0.964912\n",
      "5                   6   0.964912\n",
      "6                   7   0.956140\n",
      "7                   8   0.964912\n",
      "8                   9   0.964912\n",
      "9                  10   0.964912 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "valoresPrecisionPaso4 = []\n",
    "for max_depth, tree in zip(hiperparametro, arbolesDecisionPaso4):\n",
    "    precision = tree.score(X_test_processed, y_test)\n",
    "    valoresPrecisionPaso4.append(precision)\n",
    "\n",
    "tablaPaso4 = pd.DataFrame(\n",
    "    {\"Profundidad mÃ¡xima\": hiperparametro, \"PrecisiÃ³n\": valoresPrecisionPaso4}\n",
    ")\n",
    "print(\"Tabla de precisiÃ³n de Ã¡rboles punto 4\")\n",
    "print(tablaPaso4, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ’ŸCAMBIOS EN LOS HYPERPARAMETROSðŸ’Ÿ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "arbolesDecisionPaso6 = []\n",
    "for max_depth in hiperparametro:\n",
    "    classifier = DecisionTreeClassifier(\n",
    "        criterion=\"entropy\", splitter=\"best\", max_depth=max_depth, random_state=123\n",
    "    )\n",
    "    classifier.fit(X_train_processed, y_train)\n",
    "    arbolesDecisionPaso6.append(classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ’ŸTABLA CON SUS VALORESðŸ’Ÿ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabla de precisiÃ³n de Ã¡rboles punto 6\n",
      "   Profundidad mÃ¡xima  PrecisiÃ³n\n",
      "0                   1   0.929825\n",
      "1                   2   0.929825\n",
      "2                   3   0.973684\n",
      "3                   4   0.964912\n",
      "4                   5   0.964912\n",
      "5                   6   0.964912\n",
      "6                   7   0.991228\n",
      "7                   8   0.991228\n",
      "8                   9   0.991228\n",
      "9                  10   0.991228 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "valoresPrecisionPaso6 = []\n",
    "for max_depth, tree in zip(hiperparametro, arbolesDecisionPaso6):\n",
    "    accuracy = tree.score(X_test_processed, y_test)\n",
    "    valoresPrecisionPaso6.append(accuracy)\n",
    "\n",
    "tablaPaso6 = pd.DataFrame(\n",
    "    {\"Profundidad mÃ¡xima\": hiperparametro, \"PrecisiÃ³n\": valoresPrecisionPaso6}\n",
    ")\n",
    "print(\"Tabla de precisiÃ³n de Ã¡rboles punto 6\")\n",
    "print(tablaPaso6, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ’Ÿ3 CAMBIO EN LOS HYPERPARAMETROSðŸ’Ÿ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "arbolesDecisionPaso8 = []\n",
    "for max_depth in hiperparametro:\n",
    "    classifier = HistGradientBoostingClassifier(max_depth=max_depth, random_state=123)\n",
    "    classifier.fit(X_train_processed, y_train)\n",
    "    arbolesDecisionPaso8.append(classifier)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ’ŸTABLA CON SUS VALORESðŸ’Ÿ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabla de precisiÃ³n de Ã¡rboles punto 8\n",
      "   Profundidad mÃ¡xima  PrecisiÃ³n\n",
      "0                   1   0.973684\n",
      "1                   2   0.982456\n",
      "2                   3   0.973684\n",
      "3                   4   0.982456\n",
      "4                   5   0.982456\n",
      "5                   6   0.982456\n",
      "6                   7   0.982456\n",
      "7                   8   0.982456\n",
      "8                   9   0.982456\n",
      "9                  10   0.982456 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "valoresPrecisionPaso8 = []\n",
    "for max_depth, tree in zip(hiperparametro, arbolesDecisionPaso8):\n",
    "    accuracy = tree.score(X_test_processed, y_test)\n",
    "    valoresPrecisionPaso8.append(accuracy)\n",
    "\n",
    "tablaPaso8 = pd.DataFrame(\n",
    "    {\"Profundidad mÃ¡xima\": hiperparametro, \"PrecisiÃ³n\": valoresPrecisionPaso8}\n",
    ")\n",
    "print(\"Tabla de precisiÃ³n de Ã¡rboles punto 8\")\n",
    "print(tablaPaso8, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ’ŸENCONTRAMOS EL MEJOR ARBOLðŸ’Ÿ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El mejor Ã¡rbol es el del punto 6\n",
      "HiperparÃ¡metros del mejor Ã¡rbol:\n",
      "{'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'entropy', 'max_depth': 7, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 123, 'splitter': 'best'}\n",
      "Mejor arbol accuracy: 0.9912280701754386\n"
     ]
    }
   ],
   "source": [
    "\n",
    "arboles = [\n",
    "    max(arbolesDecisionPaso4, key=lambda tree: tree.score(X_test_processed, y_test)),\n",
    "    max(arbolesDecisionPaso6, key=lambda tree: tree.score(X_test_processed, y_test)),\n",
    "    max(arbolesDecisionPaso8, key=lambda tree: tree.score(X_test_processed, y_test)),\n",
    "]\n",
    "\n",
    "\n",
    "mejor_arbol = max(arboles, key=lambda tree: tree.score(X_test_processed, y_test))\n",
    "\n",
    "if arboles.index(mejor_arbol) == 0:\n",
    "    print(\"El mejor Ã¡rbol es el del punto 4\")\n",
    "elif arboles.index(mejor_arbol) == 1:\n",
    "    print(\"El mejor Ã¡rbol es el del punto 6\")\n",
    "else:\n",
    "    print(\"El mejor Ã¡rbol es el del punto 8\")\n",
    "\n",
    "mejor_hiperparametros = mejor_arbol.get_params()\n",
    "print(\"HiperparÃ¡metros del mejor Ã¡rbol:\")\n",
    "print(mejor_hiperparametros)\n",
    "print(\"Mejor arbol accuracy:\", mejor_arbol.score(X_test_processed, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ’ŸSE CAMBIAN LOS PARAMETROS PARA VERIFICARðŸ’Ÿ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy con max_leaf_nodes=2: 0.9649122807017544\n",
      "Accuracy con max_leaf_nodes=10: 0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "classifier_variacion1 = DecisionTreeClassifier(\n",
    "    criterion=mejor_hiperparametros[\"criterion\"],\n",
    "    splitter=mejor_hiperparametros[\"splitter\"],\n",
    "    max_depth=mejor_hiperparametros[\"max_depth\"],\n",
    "    random_state=mejor_hiperparametros[\"random_state\"],\n",
    "    max_leaf_nodes=5,\n",
    ")\n",
    "\n",
    "classifier_variacion1.fit(X_train_processed, y_train)\n",
    "accuracy_variacion1 = classifier_variacion1.score(X_test_processed, y_test)\n",
    "print(\"Accuracy con max_leaf_nodes=2:\", accuracy_variacion1)\n",
    "\n",
    "# VariaciÃ³n 2: max_leaf_nodes = 10\n",
    "classifier_variacion2 = DecisionTreeClassifier(\n",
    "    criterion=mejor_hiperparametros[\"criterion\"],\n",
    "    splitter=mejor_hiperparametros[\"splitter\"],\n",
    "    max_depth=mejor_hiperparametros[\"max_depth\"],\n",
    "    random_state=mejor_hiperparametros[\"random_state\"],\n",
    "    max_leaf_nodes=10,\n",
    ")\n",
    "\n",
    "classifier_variacion2.fit(X_train_processed, y_train)\n",
    "accuracy_variacion2 = classifier_variacion2.score(X_test_processed, y_test)\n",
    "print(\"Accuracy con max_leaf_nodes=10:\", accuracy_variacion2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>ðŸ’ŸCODIGO COMPLETOðŸ’Ÿ</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabla de precisiÃ³n de Ã¡rboles punto 4\n",
      "   Profundidad mÃ¡xima  PrecisiÃ³n\n",
      "0                   1   0.929825\n",
      "1                   2   0.929825\n",
      "2                   3   0.956140\n",
      "3                   4   0.947368\n",
      "4                   5   0.964912\n",
      "5                   6   0.964912\n",
      "6                   7   0.956140\n",
      "7                   8   0.964912\n",
      "8                   9   0.964912\n",
      "9                  10   0.964912 \n",
      "\n",
      "Tabla de precisiÃ³n de Ã¡rboles punto 6\n",
      "   Profundidad mÃ¡xima  PrecisiÃ³n\n",
      "0                   1   0.929825\n",
      "1                   2   0.929825\n",
      "2                   3   0.973684\n",
      "3                   4   0.964912\n",
      "4                   5   0.964912\n",
      "5                   6   0.964912\n",
      "6                   7   0.991228\n",
      "7                   8   0.991228\n",
      "8                   9   0.991228\n",
      "9                  10   0.991228 \n",
      "\n",
      "Tabla de precisiÃ³n de Ã¡rboles punto 8\n",
      "   Profundidad mÃ¡xima  PrecisiÃ³n\n",
      "0                   1   0.973684\n",
      "1                   2   0.982456\n",
      "2                   3   0.973684\n",
      "3                   4   0.982456\n",
      "4                   5   0.982456\n",
      "5                   6   0.982456\n",
      "6                   7   0.982456\n",
      "7                   8   0.982456\n",
      "8                   9   0.982456\n",
      "9                  10   0.982456 \n",
      "\n",
      "El mejor Ã¡rbol es el del punto 6\n",
      "HiperparÃ¡metros del mejor Ã¡rbol:\n",
      "{'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'entropy', 'max_depth': 7, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 123, 'splitter': 'best'}\n",
      "Mejor arbol accuracy: 0.9912280701754386\n",
      "Accuracy con max_leaf_nodes=2: 0.9649122807017544\n",
      "Accuracy con max_leaf_nodes=10: 0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "# 1: Leer el archivo breastCancer.csv\n",
    "\n",
    "data = pd.read_csv(\"breastCancer.csv\")\n",
    "\n",
    "# 2: Seleccionar aleatoriamente el 80% del conjunto de datos para entrenar y el 20% restante para las pruebas\n",
    "X = data.drop(\"diagnosis\", axis=1)\n",
    "y = data[\"diagnosis\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=123\n",
    ") \n",
    "\n",
    "# 3: Utilizar una estrategia para normalizar los datos.\n",
    "# CodificaciÃ³n one-hot para variables categÃ³ricas y transformaciones para variables numÃ©ricas\n",
    "numericas = [\"radius_mean\",\n",
    "              \"texture_mean\", \n",
    "              \"perimeter_mean\", \n",
    "              \"area_mean\", \n",
    "              \"smoothness_mean\", \n",
    "              \"compactness_mean\", \n",
    "              \"symmetry_mean\", \n",
    "              \"fractal_dimension_mean\", \n",
    "              \"radius_worst\",\n",
    "              \"texture_worst\",\n",
    "              \"perimeter_worst\",\n",
    "              \"area_worst\",\n",
    "              \"smoothness_worst\",\n",
    "              \"compactness_worst\",\n",
    "              \"symmetry_worst\",\n",
    "              \"fractal_dimension_worst\",]\n",
    "\n",
    "\n",
    "num_transformer = Pipeline(\n",
    "    steps=[(\"imputer\", SimpleImputer(strategy=\"median\")), (\"scaler\", StandardScaler())]\n",
    ")\n",
    "\n",
    "modificacionesPreProcesado = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", num_transformer, numericas),\n",
    "    ]\n",
    ")\n",
    "\n",
    "X_train_processed = modificacionesPreProcesado.fit_transform(X_train)\n",
    "X_test_processed = modificacionesPreProcesado.transform(X_test)\n",
    "\n",
    "# 4: Configurar los hiperparÃ¡metros del Ã¡rbol de decisiÃ³n de la siguiente manera: criterion=â€™giniâ€™,\n",
    "#splitter=â€™bestâ€™, y random_state=123. Obtener 10 Ã¡rboles de decisiÃ³n que resultan de modificar el hiperparÃ¡metro max_depth desde 1 hasta 10 de 1 en 1.\n",
    "\n",
    "hiperparametro = range(1, 11, 1)\n",
    "\n",
    "arbolesDecisionPaso4 = []\n",
    "for max_depth in hiperparametro:\n",
    "    classifier = DecisionTreeClassifier(\n",
    "        criterion=\"gini\", splitter=\"best\", max_depth=max_depth, random_state=123\n",
    "    )\n",
    "    classifier.fit(X_train_processed, y_train)\n",
    "    arbolesDecisionPaso4.append(classifier)\n",
    "\n",
    "# 5: Incluya en el notebook una tabla con el accuracy para los 10 Ã¡rboles del punto anterior\n",
    "\n",
    "valoresPrecisionPaso4 = []\n",
    "for max_depth, tree in zip(hiperparametro, arbolesDecisionPaso4):\n",
    "    precision = tree.score(X_test_processed, y_test)\n",
    "    valoresPrecisionPaso4.append(precision)\n",
    "\n",
    "tablaPaso4 = pd.DataFrame(\n",
    "    {\"Profundidad mÃ¡xima\": hiperparametro, \"PrecisiÃ³n\": valoresPrecisionPaso4}\n",
    ")\n",
    "print(\"Tabla de precisiÃ³n de Ã¡rboles punto 4\")\n",
    "print(tablaPaso4, \"\\n\")\n",
    "\n",
    "# 6: Repita el mismo procedimiento del punto 4 usando como hiperparÃ¡metros criterion=â€™entropyâ€™,splitter=â€™bestâ€™, random_state=123,\n",
    "# y variando el hiperparÃ¡metro max_depth desde 1 hasta 10 de 1 en 1.\n",
    "\n",
    "arbolesDecisionPaso6 = []\n",
    "for max_depth in hiperparametro:\n",
    "    classifier = DecisionTreeClassifier(\n",
    "        criterion=\"entropy\", splitter=\"best\", max_depth=max_depth, random_state=123\n",
    "    )\n",
    "    classifier.fit(X_train_processed, y_train)\n",
    "    arbolesDecisionPaso6.append(classifier)\n",
    "\n",
    "# 7: Incluya en el notebook una tabla con el accuracy para los 10 Ã¡rboles del punto anterior.\n",
    "\n",
    "valoresPrecisionPaso6 = []\n",
    "for max_depth, tree in zip(hiperparametro, arbolesDecisionPaso6):\n",
    "    accuracy = tree.score(X_test_processed, y_test)\n",
    "    valoresPrecisionPaso6.append(accuracy)\n",
    "\n",
    "tablaPaso6 = pd.DataFrame(\n",
    "    {\"Profundidad mÃ¡xima\": hiperparametro, \"PrecisiÃ³n\": valoresPrecisionPaso6}\n",
    ")\n",
    "print(\"Tabla de precisiÃ³n de Ã¡rboles punto 6\")\n",
    "print(tablaPaso6, \"\\n\")\n",
    "\n",
    "# 8: Repita el mismo procedimiento del punto 4 usando como hiperparÃ¡metros criterion=â€™entropyâ€™, splitter=â€™randomâ€™, random_state=123,\n",
    "# y variando el hiperparÃ¡metro max_depth desde 1 hasta 10 de 1 en 1.\n",
    "\n",
    "arbolesDecisionPaso8 = []\n",
    "for max_depth in hiperparametro:\n",
    "    classifier = HistGradientBoostingClassifier(max_depth=max_depth, random_state=123)\n",
    "    classifier.fit(X_train_processed, y_train)\n",
    "    arbolesDecisionPaso8.append(classifier)\n",
    "\n",
    "# 9: Incluya en el notebook una tabla con el accuracy para los 10 Ã¡rboles del punto anterior.\n",
    "    \n",
    "valoresPrecisionPaso8 = []\n",
    "for max_depth, tree in zip(hiperparametro, arbolesDecisionPaso8):\n",
    "    accuracy = tree.score(X_test_processed, y_test)\n",
    "    valoresPrecisionPaso8.append(accuracy)\n",
    "\n",
    "tablaPaso8 = pd.DataFrame(\n",
    "    {\"Profundidad mÃ¡xima\": hiperparametro, \"PrecisiÃ³n\": valoresPrecisionPaso8}\n",
    ")\n",
    "print(\"Tabla de precisiÃ³n de Ã¡rboles punto 8\")\n",
    "print(tablaPaso8, \"\\n\")\n",
    "\n",
    "# 10: Indique en el notebook los hiperparÃ¡metros que por el momento le permiten obtener el Ã¡rbol con mayor accuracy\n",
    "\n",
    "arboles = [\n",
    "    max(arbolesDecisionPaso4, key=lambda tree: tree.score(X_test_processed, y_test)),\n",
    "    max(arbolesDecisionPaso6, key=lambda tree: tree.score(X_test_processed, y_test)),\n",
    "    max(arbolesDecisionPaso8, key=lambda tree: tree.score(X_test_processed, y_test)),\n",
    "]\n",
    "\n",
    "\n",
    "mejor_arbol = max(arboles, key=lambda tree: tree.score(X_test_processed, y_test))\n",
    "\n",
    "if arboles.index(mejor_arbol) == 0:\n",
    "    print(\"El mejor Ã¡rbol es el del punto 4\")\n",
    "elif arboles.index(mejor_arbol) == 1:\n",
    "    print(\"El mejor Ã¡rbol es el del punto 6\")\n",
    "else:\n",
    "    print(\"El mejor Ã¡rbol es el del punto 8\")\n",
    "\n",
    "mejor_hiperparametros = mejor_arbol.get_params()\n",
    "print(\"HiperparÃ¡metros del mejor Ã¡rbol:\")\n",
    "print(mejor_hiperparametros)\n",
    "print(\"Mejor arbol accuracy:\", mejor_arbol.score(X_test_processed, y_test))\n",
    "\n",
    "# 11: Seleccione uno de los hiperparÃ¡metros disponibles en la documentaciÃ³n (https://scikitlearn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html) que sea diferente al criterion,\n",
    "#splitter, max_depth, y random_state. Realice dos variaciones en el hiperparÃ¡metro seleccionado manteniendo los otros hiperparÃ¡metros del punto anterior\n",
    "\n",
    "# VariaciÃ³n 1: max_leaf_nodes = 5\n",
    "classifier_variacion1 = DecisionTreeClassifier(\n",
    "    criterion=mejor_hiperparametros[\"criterion\"],\n",
    "    splitter=mejor_hiperparametros[\"splitter\"],\n",
    "    max_depth=mejor_hiperparametros[\"max_depth\"],\n",
    "    random_state=mejor_hiperparametros[\"random_state\"],\n",
    "    max_leaf_nodes=5,\n",
    ")\n",
    "\n",
    "classifier_variacion1.fit(X_train_processed, y_train)\n",
    "accuracy_variacion1 = classifier_variacion1.score(X_test_processed, y_test)\n",
    "print(\"Accuracy con max_leaf_nodes=2:\", accuracy_variacion1)\n",
    "\n",
    "# VariaciÃ³n 2: max_leaf_nodes = 10\n",
    "classifier_variacion2 = DecisionTreeClassifier(\n",
    "    criterion=mejor_hiperparametros[\"criterion\"],\n",
    "    splitter=mejor_hiperparametros[\"splitter\"],\n",
    "    max_depth=mejor_hiperparametros[\"max_depth\"],\n",
    "    random_state=mejor_hiperparametros[\"random_state\"],\n",
    "    max_leaf_nodes=10,\n",
    ")\n",
    "\n",
    "classifier_variacion2.fit(X_train_processed, y_train)\n",
    "accuracy_variacion2 = classifier_variacion2.score(X_test_processed, y_test)\n",
    "print(\"Accuracy con max_leaf_nodes=10:\", accuracy_variacion2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>ðŸ’ŸCONCLUSIONðŸ’Ÿ</center>\n",
    "\n",
    "Podemos concluir que cambiando el max_leaf_nodes a los valores de 2 y 10 se llega a una Accuracy de 0.9649122807017544 y 0.9736842105263158 respectivamente, lo cual nos da un resultado mas insatisfactible que nuestro mejor arbol que posee un Accuracy de 0.9912280701754386"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
