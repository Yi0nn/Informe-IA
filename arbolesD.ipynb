{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>💟INFORME MACHING LEARNING💟</center>\n",
    "\n",
    "El objetivo de este informe es crear dos notebooks. Uno donde se utilice la técnica de redes neuronales\n",
    "y otro para la técnica de árboles de decisión, todo esto para determinar los hiperparámetros óptimos para obtener la mayor precisión posible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "💟INTEGRANTES💟\n",
    "* Isabela Rosero 2128720\n",
    "* Luisa Cardenas 1823494 \n",
    "* Stefhania Noguera 2125854"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "💟IMPORTACIONES💟"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "💟LEER EL ARCHIVO CSV💟"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1: Leer el archivo breastCancer.csv\n",
    "\n",
    "data = pd.read_csv(\"breastCancer.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "💟SELECCIONAR EL 80% DEL CONJUNTO DE DATOS Y EL 20 PARA PRUEBAS💟"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2: Seleccionar aleatoriamente el 80% del conjunto de datos para entrenar y el 20% restante para las pruebas\n",
    "X = data.drop(\"diagnosis\", axis=1)\n",
    "y = data[\"diagnosis\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=123\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "💟NORMALIZAR LOS DATOS💟"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "numericas = [\"radius_mean\",\n",
    "              \"texture_mean\", \n",
    "              \"perimeter_mean\", \n",
    "              \"area_mean\", \n",
    "              \"smoothness_mean\", \n",
    "              \"compactness_mean\", \n",
    "              \"symmetry_mean\", \n",
    "              \"fractal_dimension_mean\", \n",
    "              \"radius_worst\",\n",
    "              \"texture_worst\",\n",
    "              \"perimeter_worst\",\n",
    "              \"area_worst\",\n",
    "              \"smoothness_worst\",\n",
    "              \"compactness_worst\",\n",
    "              \"symmetry_worst\",\n",
    "              \"fractal_dimension_worst\",]\n",
    "\n",
    "\n",
    "num_transformer = Pipeline(\n",
    "    steps=[(\"imputer\", SimpleImputer(strategy=\"median\")), (\"scaler\", StandardScaler())]\n",
    ")\n",
    "\n",
    "modificacionesPreProcesado = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", num_transformer, numericas),\n",
    "    ]\n",
    ")\n",
    "\n",
    "X_train_processed = modificacionesPreProcesado.fit_transform(X_train)\n",
    "X_test_processed = modificacionesPreProcesado.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "💟CONFIGURAR LOS HPERPARAMETROS DEL ARBOL💟"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "hiperparametro = range(1, 11, 1)\n",
    "\n",
    "arbolesDecisionPaso4 = []\n",
    "for max_depth in hiperparametro:\n",
    "    classifier = DecisionTreeClassifier(\n",
    "        criterion=\"gini\", splitter=\"best\", max_depth=max_depth, random_state=123\n",
    "    )\n",
    "    classifier.fit(X_train_processed, y_train)\n",
    "    arbolesDecisionPaso4.append(classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "💟TABLA CON LOS VALORES💟"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabla de precisión de árboles punto 4\n",
      "   Profundidad máxima  Precisión\n",
      "0                   1   0.929825\n",
      "1                   2   0.929825\n",
      "2                   3   0.956140\n",
      "3                   4   0.947368\n",
      "4                   5   0.964912\n",
      "5                   6   0.964912\n",
      "6                   7   0.956140\n",
      "7                   8   0.964912\n",
      "8                   9   0.964912\n",
      "9                  10   0.964912 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "valoresPrecisionPaso4 = []\n",
    "for max_depth, tree in zip(hiperparametro, arbolesDecisionPaso4):\n",
    "    precision = tree.score(X_test_processed, y_test)\n",
    "    valoresPrecisionPaso4.append(precision)\n",
    "\n",
    "tablaPaso4 = pd.DataFrame(\n",
    "    {\"Profundidad máxima\": hiperparametro, \"Precisión\": valoresPrecisionPaso4}\n",
    ")\n",
    "print(\"Tabla de precisión de árboles punto 4\")\n",
    "print(tablaPaso4, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "💟CAMBIOS EN LOS HYPERPARAMETROS💟"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "arbolesDecisionPaso6 = []\n",
    "for max_depth in hiperparametro:\n",
    "    classifier = DecisionTreeClassifier(\n",
    "        criterion=\"entropy\", splitter=\"best\", max_depth=max_depth, random_state=123\n",
    "    )\n",
    "    classifier.fit(X_train_processed, y_train)\n",
    "    arbolesDecisionPaso6.append(classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "💟TABLA CON SUS VALORES💟"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabla de precisión de árboles punto 6\n",
      "   Profundidad máxima  Precisión\n",
      "0                   1   0.929825\n",
      "1                   2   0.929825\n",
      "2                   3   0.973684\n",
      "3                   4   0.964912\n",
      "4                   5   0.964912\n",
      "5                   6   0.964912\n",
      "6                   7   0.991228\n",
      "7                   8   0.991228\n",
      "8                   9   0.991228\n",
      "9                  10   0.991228 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "valoresPrecisionPaso6 = []\n",
    "for max_depth, tree in zip(hiperparametro, arbolesDecisionPaso6):\n",
    "    accuracy = tree.score(X_test_processed, y_test)\n",
    "    valoresPrecisionPaso6.append(accuracy)\n",
    "\n",
    "tablaPaso6 = pd.DataFrame(\n",
    "    {\"Profundidad máxima\": hiperparametro, \"Precisión\": valoresPrecisionPaso6}\n",
    ")\n",
    "print(\"Tabla de precisión de árboles punto 6\")\n",
    "print(tablaPaso6, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "💟3 CAMBIO EN LOS HYPERPARAMETROS💟"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "arbolesDecisionPaso8 = []\n",
    "for max_depth in hiperparametro:\n",
    "    classifier = HistGradientBoostingClassifier(max_depth=max_depth, random_state=123)\n",
    "    classifier.fit(X_train_processed, y_train)\n",
    "    arbolesDecisionPaso8.append(classifier)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "💟TABLA CON SUS VALORES💟"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabla de precisión de árboles punto 8\n",
      "   Profundidad máxima  Precisión\n",
      "0                   1   0.973684\n",
      "1                   2   0.982456\n",
      "2                   3   0.973684\n",
      "3                   4   0.982456\n",
      "4                   5   0.982456\n",
      "5                   6   0.982456\n",
      "6                   7   0.982456\n",
      "7                   8   0.982456\n",
      "8                   9   0.982456\n",
      "9                  10   0.982456 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "valoresPrecisionPaso8 = []\n",
    "for max_depth, tree in zip(hiperparametro, arbolesDecisionPaso8):\n",
    "    accuracy = tree.score(X_test_processed, y_test)\n",
    "    valoresPrecisionPaso8.append(accuracy)\n",
    "\n",
    "tablaPaso8 = pd.DataFrame(\n",
    "    {\"Profundidad máxima\": hiperparametro, \"Precisión\": valoresPrecisionPaso8}\n",
    ")\n",
    "print(\"Tabla de precisión de árboles punto 8\")\n",
    "print(tablaPaso8, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "💟ENCONTRAMOS EL MEJOR ARBOL💟"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El mejor árbol es el del punto 6\n",
      "Hiperparámetros del mejor árbol:\n",
      "{'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'entropy', 'max_depth': 7, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 123, 'splitter': 'best'}\n",
      "Mejor arbol accuracy: 0.9912280701754386\n"
     ]
    }
   ],
   "source": [
    "\n",
    "arboles = [\n",
    "    max(arbolesDecisionPaso4, key=lambda tree: tree.score(X_test_processed, y_test)),\n",
    "    max(arbolesDecisionPaso6, key=lambda tree: tree.score(X_test_processed, y_test)),\n",
    "    max(arbolesDecisionPaso8, key=lambda tree: tree.score(X_test_processed, y_test)),\n",
    "]\n",
    "\n",
    "\n",
    "mejor_arbol = max(arboles, key=lambda tree: tree.score(X_test_processed, y_test))\n",
    "\n",
    "if arboles.index(mejor_arbol) == 0:\n",
    "    print(\"El mejor árbol es el del punto 4\")\n",
    "elif arboles.index(mejor_arbol) == 1:\n",
    "    print(\"El mejor árbol es el del punto 6\")\n",
    "else:\n",
    "    print(\"El mejor árbol es el del punto 8\")\n",
    "\n",
    "mejor_hiperparametros = mejor_arbol.get_params()\n",
    "print(\"Hiperparámetros del mejor árbol:\")\n",
    "print(mejor_hiperparametros)\n",
    "print(\"Mejor arbol accuracy:\", mejor_arbol.score(X_test_processed, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "💟SE CAMBIAN LOS PARAMETROS PARA VERIFICAR💟"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy con max_leaf_nodes=2: 0.9649122807017544\n",
      "Accuracy con max_leaf_nodes=10: 0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "classifier_variacion1 = DecisionTreeClassifier(\n",
    "    criterion=mejor_hiperparametros[\"criterion\"],\n",
    "    splitter=mejor_hiperparametros[\"splitter\"],\n",
    "    max_depth=mejor_hiperparametros[\"max_depth\"],\n",
    "    random_state=mejor_hiperparametros[\"random_state\"],\n",
    "    max_leaf_nodes=5,\n",
    ")\n",
    "\n",
    "classifier_variacion1.fit(X_train_processed, y_train)\n",
    "accuracy_variacion1 = classifier_variacion1.score(X_test_processed, y_test)\n",
    "print(\"Accuracy con max_leaf_nodes=2:\", accuracy_variacion1)\n",
    "\n",
    "# Variación 2: max_leaf_nodes = 10\n",
    "classifier_variacion2 = DecisionTreeClassifier(\n",
    "    criterion=mejor_hiperparametros[\"criterion\"],\n",
    "    splitter=mejor_hiperparametros[\"splitter\"],\n",
    "    max_depth=mejor_hiperparametros[\"max_depth\"],\n",
    "    random_state=mejor_hiperparametros[\"random_state\"],\n",
    "    max_leaf_nodes=10,\n",
    ")\n",
    "\n",
    "classifier_variacion2.fit(X_train_processed, y_train)\n",
    "accuracy_variacion2 = classifier_variacion2.score(X_test_processed, y_test)\n",
    "print(\"Accuracy con max_leaf_nodes=10:\", accuracy_variacion2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>💟CODIGO COMPLETO💟</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabla de precisión de árboles punto 4\n",
      "   Profundidad máxima  Precisión\n",
      "0                   1   0.929825\n",
      "1                   2   0.929825\n",
      "2                   3   0.956140\n",
      "3                   4   0.947368\n",
      "4                   5   0.964912\n",
      "5                   6   0.964912\n",
      "6                   7   0.956140\n",
      "7                   8   0.964912\n",
      "8                   9   0.964912\n",
      "9                  10   0.964912 \n",
      "\n",
      "Tabla de precisión de árboles punto 6\n",
      "   Profundidad máxima  Precisión\n",
      "0                   1   0.929825\n",
      "1                   2   0.929825\n",
      "2                   3   0.973684\n",
      "3                   4   0.964912\n",
      "4                   5   0.964912\n",
      "5                   6   0.964912\n",
      "6                   7   0.991228\n",
      "7                   8   0.991228\n",
      "8                   9   0.991228\n",
      "9                  10   0.991228 \n",
      "\n",
      "Tabla de precisión de árboles punto 8\n",
      "   Profundidad máxima  Precisión\n",
      "0                   1   0.973684\n",
      "1                   2   0.982456\n",
      "2                   3   0.973684\n",
      "3                   4   0.982456\n",
      "4                   5   0.982456\n",
      "5                   6   0.982456\n",
      "6                   7   0.982456\n",
      "7                   8   0.982456\n",
      "8                   9   0.982456\n",
      "9                  10   0.982456 \n",
      "\n",
      "El mejor árbol es el del punto 6\n",
      "Hiperparámetros del mejor árbol:\n",
      "{'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'entropy', 'max_depth': 7, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 123, 'splitter': 'best'}\n",
      "Mejor arbol accuracy: 0.9912280701754386\n",
      "Accuracy con max_leaf_nodes=2: 0.9649122807017544\n",
      "Accuracy con max_leaf_nodes=10: 0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "# 1: Leer el archivo breastCancer.csv\n",
    "\n",
    "data = pd.read_csv(\"breastCancer.csv\")\n",
    "\n",
    "# 2: Seleccionar aleatoriamente el 80% del conjunto de datos para entrenar y el 20% restante para las pruebas\n",
    "X = data.drop(\"diagnosis\", axis=1)\n",
    "y = data[\"diagnosis\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=123\n",
    ") \n",
    "\n",
    "# 3: Utilizar una estrategia para normalizar los datos.\n",
    "# Codificación one-hot para variables categóricas y transformaciones para variables numéricas\n",
    "numericas = [\"radius_mean\",\n",
    "              \"texture_mean\", \n",
    "              \"perimeter_mean\", \n",
    "              \"area_mean\", \n",
    "              \"smoothness_mean\", \n",
    "              \"compactness_mean\", \n",
    "              \"symmetry_mean\", \n",
    "              \"fractal_dimension_mean\", \n",
    "              \"radius_worst\",\n",
    "              \"texture_worst\",\n",
    "              \"perimeter_worst\",\n",
    "              \"area_worst\",\n",
    "              \"smoothness_worst\",\n",
    "              \"compactness_worst\",\n",
    "              \"symmetry_worst\",\n",
    "              \"fractal_dimension_worst\",]\n",
    "\n",
    "\n",
    "num_transformer = Pipeline(\n",
    "    steps=[(\"imputer\", SimpleImputer(strategy=\"median\")), (\"scaler\", StandardScaler())]\n",
    ")\n",
    "\n",
    "modificacionesPreProcesado = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", num_transformer, numericas),\n",
    "    ]\n",
    ")\n",
    "\n",
    "X_train_processed = modificacionesPreProcesado.fit_transform(X_train)\n",
    "X_test_processed = modificacionesPreProcesado.transform(X_test)\n",
    "\n",
    "# 4: Configurar los hiperparámetros del árbol de decisión de la siguiente manera: criterion=’gini’,\n",
    "#splitter=’best’, y random_state=123. Obtener 10 árboles de decisión que resultan de modificar el hiperparámetro max_depth desde 1 hasta 10 de 1 en 1.\n",
    "\n",
    "hiperparametro = range(1, 11, 1)\n",
    "\n",
    "arbolesDecisionPaso4 = []\n",
    "for max_depth in hiperparametro:\n",
    "    classifier = DecisionTreeClassifier(\n",
    "        criterion=\"gini\", splitter=\"best\", max_depth=max_depth, random_state=123\n",
    "    )\n",
    "    classifier.fit(X_train_processed, y_train)\n",
    "    arbolesDecisionPaso4.append(classifier)\n",
    "\n",
    "# 5: Incluya en el notebook una tabla con el accuracy para los 10 árboles del punto anterior\n",
    "\n",
    "valoresPrecisionPaso4 = []\n",
    "for max_depth, tree in zip(hiperparametro, arbolesDecisionPaso4):\n",
    "    precision = tree.score(X_test_processed, y_test)\n",
    "    valoresPrecisionPaso4.append(precision)\n",
    "\n",
    "tablaPaso4 = pd.DataFrame(\n",
    "    {\"Profundidad máxima\": hiperparametro, \"Precisión\": valoresPrecisionPaso4}\n",
    ")\n",
    "print(\"Tabla de precisión de árboles punto 4\")\n",
    "print(tablaPaso4, \"\\n\")\n",
    "\n",
    "# 6: Repita el mismo procedimiento del punto 4 usando como hiperparámetros criterion=’entropy’,splitter=’best’, random_state=123,\n",
    "# y variando el hiperparámetro max_depth desde 1 hasta 10 de 1 en 1.\n",
    "\n",
    "arbolesDecisionPaso6 = []\n",
    "for max_depth in hiperparametro:\n",
    "    classifier = DecisionTreeClassifier(\n",
    "        criterion=\"entropy\", splitter=\"best\", max_depth=max_depth, random_state=123\n",
    "    )\n",
    "    classifier.fit(X_train_processed, y_train)\n",
    "    arbolesDecisionPaso6.append(classifier)\n",
    "\n",
    "# 7: Incluya en el notebook una tabla con el accuracy para los 10 árboles del punto anterior.\n",
    "\n",
    "valoresPrecisionPaso6 = []\n",
    "for max_depth, tree in zip(hiperparametro, arbolesDecisionPaso6):\n",
    "    accuracy = tree.score(X_test_processed, y_test)\n",
    "    valoresPrecisionPaso6.append(accuracy)\n",
    "\n",
    "tablaPaso6 = pd.DataFrame(\n",
    "    {\"Profundidad máxima\": hiperparametro, \"Precisión\": valoresPrecisionPaso6}\n",
    ")\n",
    "print(\"Tabla de precisión de árboles punto 6\")\n",
    "print(tablaPaso6, \"\\n\")\n",
    "\n",
    "# 8: Repita el mismo procedimiento del punto 4 usando como hiperparámetros criterion=’entropy’, splitter=’random’, random_state=123,\n",
    "# y variando el hiperparámetro max_depth desde 1 hasta 10 de 1 en 1.\n",
    "\n",
    "arbolesDecisionPaso8 = []\n",
    "for max_depth in hiperparametro:\n",
    "    classifier = HistGradientBoostingClassifier(max_depth=max_depth, random_state=123)\n",
    "    classifier.fit(X_train_processed, y_train)\n",
    "    arbolesDecisionPaso8.append(classifier)\n",
    "\n",
    "# 9: Incluya en el notebook una tabla con el accuracy para los 10 árboles del punto anterior.\n",
    "    \n",
    "valoresPrecisionPaso8 = []\n",
    "for max_depth, tree in zip(hiperparametro, arbolesDecisionPaso8):\n",
    "    accuracy = tree.score(X_test_processed, y_test)\n",
    "    valoresPrecisionPaso8.append(accuracy)\n",
    "\n",
    "tablaPaso8 = pd.DataFrame(\n",
    "    {\"Profundidad máxima\": hiperparametro, \"Precisión\": valoresPrecisionPaso8}\n",
    ")\n",
    "print(\"Tabla de precisión de árboles punto 8\")\n",
    "print(tablaPaso8, \"\\n\")\n",
    "\n",
    "# 10: Indique en el notebook los hiperparámetros que por el momento le permiten obtener el árbol con mayor accuracy\n",
    "\n",
    "arboles = [\n",
    "    max(arbolesDecisionPaso4, key=lambda tree: tree.score(X_test_processed, y_test)),\n",
    "    max(arbolesDecisionPaso6, key=lambda tree: tree.score(X_test_processed, y_test)),\n",
    "    max(arbolesDecisionPaso8, key=lambda tree: tree.score(X_test_processed, y_test)),\n",
    "]\n",
    "\n",
    "\n",
    "mejor_arbol = max(arboles, key=lambda tree: tree.score(X_test_processed, y_test))\n",
    "\n",
    "if arboles.index(mejor_arbol) == 0:\n",
    "    print(\"El mejor árbol es el del punto 4\")\n",
    "elif arboles.index(mejor_arbol) == 1:\n",
    "    print(\"El mejor árbol es el del punto 6\")\n",
    "else:\n",
    "    print(\"El mejor árbol es el del punto 8\")\n",
    "\n",
    "mejor_hiperparametros = mejor_arbol.get_params()\n",
    "print(\"Hiperparámetros del mejor árbol:\")\n",
    "print(mejor_hiperparametros)\n",
    "print(\"Mejor arbol accuracy:\", mejor_arbol.score(X_test_processed, y_test))\n",
    "\n",
    "# 11: Seleccione uno de los hiperparámetros disponibles en la documentación (https://scikitlearn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html) que sea diferente al criterion,\n",
    "#splitter, max_depth, y random_state. Realice dos variaciones en el hiperparámetro seleccionado manteniendo los otros hiperparámetros del punto anterior\n",
    "\n",
    "# Variación 1: max_leaf_nodes = 5\n",
    "classifier_variacion1 = DecisionTreeClassifier(\n",
    "    criterion=mejor_hiperparametros[\"criterion\"],\n",
    "    splitter=mejor_hiperparametros[\"splitter\"],\n",
    "    max_depth=mejor_hiperparametros[\"max_depth\"],\n",
    "    random_state=mejor_hiperparametros[\"random_state\"],\n",
    "    max_leaf_nodes=5,\n",
    ")\n",
    "\n",
    "classifier_variacion1.fit(X_train_processed, y_train)\n",
    "accuracy_variacion1 = classifier_variacion1.score(X_test_processed, y_test)\n",
    "print(\"Accuracy con max_leaf_nodes=2:\", accuracy_variacion1)\n",
    "\n",
    "# Variación 2: max_leaf_nodes = 10\n",
    "classifier_variacion2 = DecisionTreeClassifier(\n",
    "    criterion=mejor_hiperparametros[\"criterion\"],\n",
    "    splitter=mejor_hiperparametros[\"splitter\"],\n",
    "    max_depth=mejor_hiperparametros[\"max_depth\"],\n",
    "    random_state=mejor_hiperparametros[\"random_state\"],\n",
    "    max_leaf_nodes=10,\n",
    ")\n",
    "\n",
    "classifier_variacion2.fit(X_train_processed, y_train)\n",
    "accuracy_variacion2 = classifier_variacion2.score(X_test_processed, y_test)\n",
    "print(\"Accuracy con max_leaf_nodes=10:\", accuracy_variacion2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>💟CONCLUSION💟</center>\n",
    "\n",
    "Podemos concluir que cambiando el max_leaf_nodes a los valores de 2 y 10 se llega a una Accuracy de 0.9649122807017544 y 0.9736842105263158 respectivamente, lo cual nos da un resultado mas insatisfactible que nuestro mejor arbol que posee un Accuracy de 0.9912280701754386"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
