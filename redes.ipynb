{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>INFORME MACHING LEARNING</center>\n",
    "\n",
    "El objetivo de este informe es crear dos notebooks. Uno donde se utilice la t茅cnica de redes neuronales\n",
    "y otro para la t茅cnica de 谩rboles de decisi贸n, todo esto para determinar los hiperpar谩metros 贸ptimos para obtener la mayor precisi贸n posible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INTEGRANTES\n",
    "* Isabela Rosero 2128720\n",
    "* Luisa Cardenas 1823494 \n",
    "* Stefhania Noguera 2125854"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMO CORRER EL ARCHIVO\n",
    "* Instalar pandas con *pip install pandas*\n",
    "* Instalar sklearn con *pip install  scikit-learn*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORTACIONES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar bibliotecas necesarias\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LEER EL ARCHIVO CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Leer el archivo breastCancer.csv.\n",
    "data = pd.read_csv('breastCancer.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SELECCIONAR EL 80% DEL CONJUNTO DE DATOS Y EL 20 PARA PRUEBAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Seleccionar aleatoriamente el 80% del conjunto de datos para entrenar y el 20% restante para las pruebas.\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NORMALIZAR LOS DATOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Utilizar una estrategia para normalizar los datos.\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(train_data.iloc[:, :-1])  # Excluir la columna de diagn贸stico\n",
    "y_train = train_data['diagnosis']\n",
    "\n",
    "X_test = scaler.transform(test_data.iloc[:, :-1])\n",
    "y_test = test_data['diagnosis']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONSTRUIR 5 REDES CON VARIACIONES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Activation Solver Hidden Layer Sizes  Accuracy    Confusion Matrix\n",
      "0       relu   adam         (200, 300)  0.991228  [[73, 0], [1, 40]]\n",
      "1       tanh  lbfgs       (10, 20, 10)  0.938596  [[70, 3], [4, 37]]\n",
      "2   logistic    sgd       (20, 15, 10)  0.640351  [[73, 0], [41, 0]]\n",
      "3   identity   adam     (10, 10, 5, 5)  0.973684  [[73, 0], [3, 38]]\n",
      "4       tanh   adam          (150, 75)  0.964912  [[72, 1], [3, 38]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 4. Construir 5 redes neuronales variando la funci贸n de activaci贸n, el solver, y la cantidad de capas ocultas y de neuronas por cada capa oculta.\n",
    "results = []\n",
    "\n",
    "# Seleccionar combinaciones espec铆ficas\n",
    "combinations = [\n",
    "    ('relu', 'adam', (200 , 300)),\n",
    "    ('tanh', 'lbfgs', (10, 20, 10)),\n",
    "    ('logistic', 'sgd', (20, 15, 10)),\n",
    "    ('identity', 'adam', (10, 10, 5, 5)),\n",
    "    ('tanh', 'adam', (150, 75)),\n",
    "]\n",
    "\n",
    "for activation, solver, hidden_layer_size in combinations:\n",
    "    # Crear y entrenar el modelo\n",
    "    model = MLPClassifier(activation=activation, solver=solver, hidden_layer_sizes=hidden_layer_size, random_state=123, max_iter=500)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Hacer predicciones\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calcular accuracy y matriz de confusi贸n\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    # Guardar resultados\n",
    "    results.append({\n",
    "        'Activation': activation,\n",
    "        'Solver': solver,\n",
    "        'Hidden Layer Sizes': hidden_layer_size,\n",
    "        'Accuracy': acc,\n",
    "        'Confusion Matrix': conf_matrix\n",
    "    })\n",
    "\n",
    "# Mostrar resultados en una tabla\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variaciones con hyperparametro alpha\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Se varia el hyperparametro de alpha\n",
      "  Activation Solver Hidden Layer Sizes  Alpha  Accuracy    Confusion Matrix\n",
      "0       relu   adam         (200, 300)    0.3  0.964912  [[72, 1], [3, 38]]\n",
      "1       relu   adam         (200, 300)    0.1  0.982456  [[72, 1], [1, 40]]\n"
     ]
    }
   ],
   "source": [
    "print(\"\")\n",
    "print(\"Se varia el hyperparametro de alpha\")\n",
    "# Entrenar primera red con alpha=0.3\n",
    "model_1 = MLPClassifier(activation='relu', solver='adam', hidden_layer_sizes=(200, 300), alpha=0.3, random_state=123, max_iter=500)\n",
    "model_1.fit(X_train, y_train)\n",
    "\n",
    "# Hacer predicciones para la primera red\n",
    "y_pred_1 = model_1.predict(X_test)\n",
    "\n",
    "# Calcular accuracy y matriz de confusi贸n para la primera red\n",
    "acc_1 = accuracy_score(y_test, y_pred_1)\n",
    "conf_matrix_1 = confusion_matrix(y_test, y_pred_1)\n",
    "\n",
    "# Guardar resultados de la primera red\n",
    "results_1 = {\n",
    "    'Activation': 'relu',\n",
    "    'Solver': 'adam',\n",
    "    'Hidden Layer Sizes': (200, 300),\n",
    "    'Alpha': 0.3,\n",
    "    'Accuracy': acc_1,\n",
    "    'Confusion Matrix': conf_matrix_1\n",
    "}\n",
    "\n",
    "# Entrenar segunda red con alpha=0.1\n",
    "model_2 = MLPClassifier(activation='relu', solver='adam', hidden_layer_sizes=(200, 300), alpha=0.1, random_state=123, max_iter=500)\n",
    "model_2.fit(X_train, y_train)\n",
    "\n",
    "# Hacer predicciones para la segunda red\n",
    "y_pred_2 = model_2.predict(X_test)\n",
    "\n",
    "# Calcular accuracy y matriz de confusi贸n para la segunda red\n",
    "acc_2 = accuracy_score(y_test, y_pred_2)\n",
    "conf_matrix_2 = confusion_matrix(y_test, y_pred_2)\n",
    "\n",
    "# Guardar resultados de la segunda red\n",
    "results_2 = {\n",
    "    'Activation': 'relu',\n",
    "    'Solver': 'adam',\n",
    "    'Hidden Layer Sizes': (200, 300),\n",
    "    'Alpha': 0.1,\n",
    "    'Accuracy': acc_2,\n",
    "    'Confusion Matrix': conf_matrix_2\n",
    "}\n",
    "\n",
    "# Mostrar resultados en una tabla\n",
    "results_df = pd.DataFrame([results_1, results_2])\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>CODIGO COMPLETO</center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Activation Solver Hidden Layer Sizes  Accuracy    Confusion Matrix\n",
      "0       relu   adam         (200, 300)  0.991228  [[73, 0], [1, 40]]\n",
      "1       tanh  lbfgs       (10, 20, 10)  0.938596  [[70, 3], [4, 37]]\n",
      "2   logistic    sgd       (20, 15, 10)  0.640351  [[73, 0], [41, 0]]\n",
      "3   identity   adam     (10, 10, 5, 5)  0.973684  [[73, 0], [3, 38]]\n",
      "4       tanh   adam          (150, 75)  0.964912  [[72, 1], [3, 38]]\n",
      "\n",
      "  Activation Solver Hidden Layer Sizes  Alpha  Accuracy    Confusion Matrix\n",
      "0       relu   adam         (200, 300)    0.3  0.964912  [[72, 1], [3, 38]]\n",
      "1       relu   adam         (200, 300)    0.1  0.982456  [[72, 1], [1, 40]]\n"
     ]
    }
   ],
   "source": [
    "# Importar bibliotecas necesarias\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# 1. Leer el archivo breastCancer.csv.\n",
    "data = pd.read_csv('breastCancer.csv')\n",
    "\n",
    "# 2. Seleccionar aleatoriamente el 80% del conjunto de datos para entrenar y el 20% restante para las pruebas.\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=123)\n",
    "\n",
    "# 3. Utilizar una estrategia para normalizar los datos.\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(train_data.iloc[:, :-1])  # Excluir la columna de diagn贸stico\n",
    "y_train = train_data['diagnosis']\n",
    "\n",
    "X_test = scaler.transform(test_data.iloc[:, :-1])\n",
    "y_test = test_data['diagnosis']\n",
    "\n",
    "# 4. Construir 5 redes neuronales variando la funci贸n de activaci贸n, el solver, y la cantidad de capas ocultas y de neuronas por cada capa oculta.\n",
    "results = []\n",
    "\n",
    "# Seleccionar combinaciones espec铆ficas\n",
    "combinations = [\n",
    "    ('relu', 'adam', (200 , 300)),\n",
    "    ('tanh', 'lbfgs', (10, 20, 10)),\n",
    "    ('logistic', 'sgd', (20, 15, 10)),\n",
    "    ('identity', 'adam', (10, 10, 5, 5)),\n",
    "    ('tanh', 'adam', (150, 75)),\n",
    "]\n",
    "\n",
    "for activation, solver, hidden_layer_size in combinations:\n",
    "    # Crear y entrenar el modelo\n",
    "    model = MLPClassifier(activation=activation, solver=solver, hidden_layer_sizes=hidden_layer_size, random_state=123, max_iter=500)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Hacer predicciones\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calcular accuracy y matriz de confusi贸n\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    # Guardar resultados\n",
    "    results.append({\n",
    "        'Activation': activation,\n",
    "        'Solver': solver,\n",
    "        'Hidden Layer Sizes': hidden_layer_size,\n",
    "        'Accuracy': acc,\n",
    "        'Confusion Matrix': conf_matrix\n",
    "    })\n",
    "\n",
    "# Mostrar resultados en una tabla\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)\n",
    "print(\"\")\n",
    "print(\"Se varia el hyperparametro de alpha\")\n",
    "\n",
    "#Variaciones con hyperparametro alpha\n",
    "\n",
    "# Entrenar primera red con alpha=0.3\n",
    "model_1 = MLPClassifier(activation='relu', solver='adam', hidden_layer_sizes=(200, 300), alpha=0.3, random_state=123, max_iter=500)\n",
    "model_1.fit(X_train, y_train)\n",
    "\n",
    "# Hacer predicciones para la primera red\n",
    "y_pred_1 = model_1.predict(X_test)\n",
    "\n",
    "# Calcular accuracy y matriz de confusi贸n para la primera red\n",
    "acc_1 = accuracy_score(y_test, y_pred_1)\n",
    "conf_matrix_1 = confusion_matrix(y_test, y_pred_1)\n",
    "\n",
    "# Guardar resultados de la primera red\n",
    "results_1 = {\n",
    "    'Activation': 'relu',\n",
    "    'Solver': 'adam',\n",
    "    'Hidden Layer Sizes': (200, 300),\n",
    "    'Alpha': 0.3,\n",
    "    'Accuracy': acc_1,\n",
    "    'Confusion Matrix': conf_matrix_1\n",
    "}\n",
    "\n",
    "# Entrenar segunda red con alpha=0.1\n",
    "model_2 = MLPClassifier(activation='relu', solver='adam', hidden_layer_sizes=(200, 300), alpha=0.1, random_state=123, max_iter=500)\n",
    "model_2.fit(X_train, y_train)\n",
    "\n",
    "# Hacer predicciones para la segunda red\n",
    "y_pred_2 = model_2.predict(X_test)\n",
    "\n",
    "# Calcular accuracy y matriz de confusi贸n para la segunda red\n",
    "acc_2 = accuracy_score(y_test, y_pred_2)\n",
    "conf_matrix_2 = confusion_matrix(y_test, y_pred_2)\n",
    "\n",
    "# Guardar resultados de la segunda red\n",
    "results_2 = {\n",
    "    'Activation': 'relu',\n",
    "    'Solver': 'adam',\n",
    "    'Hidden Layer Sizes': (200, 300),\n",
    "    'Alpha': 0.1,\n",
    "    'Accuracy': acc_2,\n",
    "    'Confusion Matrix': conf_matrix_2\n",
    "}\n",
    "\n",
    "# Mostrar resultados en una tabla\n",
    "results_df = pd.DataFrame([results_1, results_2])\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>TABLA DE RESULTADOS</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Layer Sizes|Accuracy|Confusion Matrix|\n",
    "|--|--|--|\n",
    "|0     (200, 300) |0.991228| [73, 0], [1, 40]|\n",
    "|1     (10, 20, 10) | 0.938596 | [70, 3], [4, 37]|\n",
    "|2  (20, 15, 10) | 0.640351 | [73, 0], [41, 0]|\n",
    "|3  (10, 10, 5, 5) | 0.973684 | [73, 0], [3, 38]|\n",
    "|4  (150, 75) | 0.964912 | [72, 1], [3, 38]|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hiperpar谩metros que por el momento le permiten obtener la red con mayor accuracy\n",
    "*   Con el solver \"adam\"\n",
    "*   Con una activacion \"relu\"\n",
    "*   Con un random state de 123\n",
    "\n",
    "Despues se modific贸 el hiperpar谩metro alpha \n",
    "\n",
    "Se modifico con 0.3 y 0.1 llegando a la conclusion de:\n",
    "\n",
    "El mejor accuracy lo tuvo en: 0.1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
